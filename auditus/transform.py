# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_transform.ipynb.

# %% auto 0
__all__ = ['AudioLoader', 'Resampling', 'Pooling', 'AudioEmbedding']

# %% ../nbs/01_transform.ipynb 3
import torch
import numpy as np
from fastcore.all import *
from IPython.display import Audio
from fasttransform import DisplayedTransform, Pipeline
from transformers import AutoFeatureExtractor

from .core import load_audio, AudioArray

# %% ../nbs/01_transform.ipynb 5
class AudioLoader(DisplayedTransform):
    def __init__(self, sr: int = None): store_attr()
    def encodes(self, x:str) -> AudioArray: return load_audio(x, self.sr)
    def encodes(self, x:list[str]): return [load_audio(i, self.sr) for i in x]

# %% ../nbs/01_transform.ipynb 14
class Resampling(DisplayedTransform):
    def __init__(self, target_sr: int):
        store_attr()

    def encodes(self, audio: AudioArray) -> AudioArray:
        if audio.sr == self.target_sr: return audio
        indices = np.linspace(0, len(audio.a) - 1, self._new_length(audio, self.target_sr))
        resampled = np.interp(indices, np.arange(len(audio.a)), audio.a)
        return AudioArray(resampled, self.target_sr)

    def _new_length(self, audio: AudioArray, target_sr: int) -> int:
        return int(len(audio.a) * (target_sr / audio.sr))

# %% ../nbs/01_transform.ipynb 21
class Pooling(DisplayedTransform):
    def __init__(self, pooling: str = None):
        assert pooling in [None, "mean", "max"], "Pooling must be either None (no pooling), 'mean' or 'max'."
        store_attr()

    def encodes(self, x:np.ndarray) -> np.ndarray: 
        if self.pooling is None: return x
        elif self.pooling == "mean": return x.mean(axis=1)
        elif self.pooling == "max": return x.max(axis=1)

    def encodes(self, x:torch.Tensor) -> torch.Tensor: 
        if self.pooling is None: return x
        # Torch aggregation also returns a tuple with max indices, so we need to unpack it
        elif self.pooling == "mean": return x.mean(dim=1)[0]
        elif self.pooling == "max": return x.max(dim=1)[0]

# %% ../nbs/01_transform.ipynb 36
class AudioEmbedding(DisplayedTransform):
    def __init__(self, model_name: str = "MIT/ast-finetuned-audioset-10-10-0.4593",         return_tensors: str = "np", 
                 **kwargs): 
        store_attr()
        self.model = AutoFeatureExtractor.from_pretrained(model_name, **kwargs)

    def encodes(self, x:AudioArray): 
        return self.model(x.a, sampling_rate=x.sr, return_tensors=self.return_tensors)['input_values']
